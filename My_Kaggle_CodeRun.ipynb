{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-29T02:46:31.879532Z",
     "iopub.status.busy": "2024-12-29T02:46:31.879221Z",
     "iopub.status.idle": "2024-12-29T03:07:17.242280Z",
     "shell.execute_reply": "2024-12-29T03:07:17.241209Z",
     "shell.execute_reply.started": "2024-12-29T02:46:31.879508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Class distribution: [3763  843]\n",
      "Class weights: [0.6120117 2.7319098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "<ipython-input-2-86d37c2338d1>:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  base_model.load_state_dict(torch.load(model_path))\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/20: 100%|██████████| 116/116 [00:50<00:00,  2.28it/s, Loss=0.3494, LR=0.001000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Average Loss: 0.3494\n",
      "Validation Loss: 0.1550\n",
      "Validation Accuracy: 93.17%\n",
      "Saved new best model with validation loss: 0.1550\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 116/116 [00:52<00:00,  2.22it/s, Loss=0.2473, LR=0.001000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20\n",
      "Average Loss: 0.2473\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 93.82%\n",
      "Saved new best model with validation loss: 0.1519\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 116/116 [00:53<00:00,  2.18it/s, Loss=0.1861, LR=0.001000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "Average Loss: 0.1861\n",
      "Validation Loss: 0.3580\n",
      "Validation Accuracy: 80.69%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 116/116 [00:54<00:00,  2.15it/s, Loss=0.1221, LR=0.001000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n",
      "Average Loss: 0.1221\n",
      "Validation Loss: 0.2450\n",
      "Validation Accuracy: 93.28%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 116/116 [00:54<00:00,  2.12it/s, Loss=0.1136, LR=0.001000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/20\n",
      "Average Loss: 0.1136\n",
      "Validation Loss: 0.2634\n",
      "Validation Accuracy: 94.58%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 116/116 [00:55<00:00,  2.11it/s, Loss=0.1631, LR=0.001000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20\n",
      "Average Loss: 0.1631\n",
      "Validation Loss: 0.2793\n",
      "Validation Accuracy: 87.96%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0729, LR=0.000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/20\n",
      "Average Loss: 0.0729\n",
      "Validation Loss: 0.1180\n",
      "Validation Accuracy: 96.10%\n",
      "Saved new best model with validation loss: 0.1180\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 116/116 [00:55<00:00,  2.10it/s, Loss=0.0490, LR=0.000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20\n",
      "Average Loss: 0.0490\n",
      "Validation Loss: 0.1560\n",
      "Validation Accuracy: 96.20%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 116/116 [00:55<00:00,  2.10it/s, Loss=0.0348, LR=0.000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/20\n",
      "Average Loss: 0.0348\n",
      "Validation Loss: 0.1573\n",
      "Validation Accuracy: 96.10%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0263, LR=0.000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20\n",
      "Average Loss: 0.0263\n",
      "Validation Loss: 0.1559\n",
      "Validation Accuracy: 96.10%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0291, LR=0.000100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20\n",
      "Average Loss: 0.0291\n",
      "Validation Loss: 0.1931\n",
      "Validation Accuracy: 96.20%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0138, LR=0.000010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20\n",
      "Average Loss: 0.0138\n",
      "Validation Loss: 0.1798\n",
      "Validation Accuracy: 95.44%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0096, LR=0.000010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20\n",
      "Average Loss: 0.0096\n",
      "Validation Loss: 0.2013\n",
      "Validation Accuracy: 95.66%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 116/116 [00:55<00:00,  2.08it/s, Loss=0.0193, LR=0.000010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20\n",
      "Average Loss: 0.0193\n",
      "Validation Loss: 0.2241\n",
      "Validation Accuracy: 96.42%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0118, LR=0.000010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n",
      "Average Loss: 0.0118\n",
      "Validation Loss: 0.1762\n",
      "Validation Accuracy: 95.66%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0098, LR=0.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n",
      "Average Loss: 0.0098\n",
      "Validation Loss: 0.1782\n",
      "Validation Accuracy: 95.99%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0178, LR=0.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/20\n",
      "Average Loss: 0.0178\n",
      "Validation Loss: 0.1903\n",
      "Validation Accuracy: 96.10%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0131, LR=0.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/20\n",
      "Average Loss: 0.0131\n",
      "Validation Loss: 0.1878\n",
      "Validation Accuracy: 95.66%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0125, LR=0.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/20\n",
      "Average Loss: 0.0125\n",
      "Validation Loss: 0.1884\n",
      "Validation Accuracy: 95.77%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 116/116 [00:55<00:00,  2.09it/s, Loss=0.0111, LR=0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/20\n",
      "Average Loss: 0.0111\n",
      "Validation Loss: 0.1644\n",
      "Validation Accuracy: 95.99%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.convert(\"L\")\n",
    "    image = np.array(image)\n",
    "    local_mean = np.mean(image)\n",
    "    thresh_image = np.where(image > (local_mean - 2), 255, 0)\n",
    "    return Image.fromarray(thresh_image.astype(np.uint8))\n",
    "\n",
    "\n",
    "class GlomeruliDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        image = preprocess_image(image)\n",
    "        image = image.convert(\"RGB\")\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, y_label\n",
    "\n",
    "\n",
    "class GlomeruliClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=2):\n",
    "        super(GlomeruliClassifier, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        num_features = 2048\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device\n",
    "):\n",
    "    best_loss = float(\"inf\")\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"Loss\": f\"{running_loss/(progress_bar.n+1):.4f}\",\n",
    "                    \"LR\": f'{optimizer.param_groups[0][\"lr\"]:.6f}',\n",
    "                }\n",
    "            )\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100.0 * correct / total\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Average Loss: {epoch_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"Final_model.pth\")\n",
    "            print(f\"Saved new best model with validation loss: {best_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = GlomeruliDataset(\n",
    "        csv_file=\"./train_labels.csv\",\n",
    "        img_dir=\"./ResizedTrainingSet\",\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "    labels = [int(dataset.annotations.iloc[i, 1]) for i in range(len(dataset))]\n",
    "    class_counts = np.bincount(labels)\n",
    "    total_samples = len(labels)\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "    print(\"Class distribution:\", class_counts)\n",
    "    print(\"Class weights:\", class_weights.cpu().numpy())\n",
    "\n",
    "    train_set, val_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    model_path = \"./inception_v3_google-0cc3c7bd.pth\"\n",
    "    base_model = models.inception_v3(pretrained=False)\n",
    "    base_model.load_state_dict(torch.load(model_path))\n",
    "    base_model.aux_logits = False\n",
    "    base_model.fc = nn.Identity()\n",
    "    model = GlomeruliClassifier(base_model).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.1, patience=3, verbose=True\n",
    "    )\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        num_epochs=20,\n",
    "        device=device,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T05:05:15.489396Z",
     "iopub.status.busy": "2024-12-29T05:05:15.489109Z",
     "iopub.status.idle": "2024-12-29T05:05:22.891451Z",
     "shell.execute_reply": "2024-12-29T05:05:22.890514Z",
     "shell.execute_reply.started": "2024-12-29T05:05:15.489376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-9b37f231db4e>:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/working/Final_model.pth\"))\n",
      "100%|██████████| 36/36 [00:06<00:00,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 95.75%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       941\n",
      "           1       0.83      0.97      0.89       211\n",
      "\n",
      "    accuracy                           0.96      1152\n",
      "   macro avg       0.91      0.96      0.93      1152\n",
      "weighted avg       0.96      0.96      0.96      1152\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[898  43]\n",
      " [  6 205]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.convert(\"L\")\n",
    "    image = np.array(image)\n",
    "    local_mean = np.mean(image)\n",
    "    thresh_image = np.where(image > (local_mean - 2), 255, 0)\n",
    "    return Image.fromarray(thresh_image.astype(np.uint8))\n",
    "\n",
    "\n",
    "class GlomeruliDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        image = preprocess_image(image)\n",
    "        image = image.convert(\"RGB\")\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, y_label\n",
    "\n",
    "\n",
    "class GlomeruliClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=2):\n",
    "        super(GlomeruliClassifier, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        num_features = 2048\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return accuracy, predictions, true_labels\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Data transformations\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Test data\n",
    "    test_dataset = GlomeruliDataset(\n",
    "        csv_file=\"./test_labels.csv\",  # Path to your test labels CSV\n",
    "        img_dir=\"./ResizedTestSet\",  # Path to your test images directory\n",
    "        transform=transform,\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Create a models directory in your project\n",
    "    model_path = \"./inception_v3_google-0cc3c7bd.pth\"\n",
    "\n",
    "    # Load the model with custom weights using safe loading\n",
    "    base_model = models.inception_v3(weights=None, init_weights=True)\n",
    "    base_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    base_model.fc = nn.Identity()\n",
    "    model = GlomeruliClassifier(base_model).to(device)\n",
    "\n",
    "    # Load the trained model\n",
    "    model.load_state_dict(torch.load(\"./Final_model.pth\"))\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy, predictions, true_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(true_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T05:01:56.528452Z",
     "iopub.status.busy": "2024-12-29T05:01:56.528163Z",
     "iopub.status.idle": "2024-12-29T05:02:28.153144Z",
     "shell.execute_reply": "2024-12-29T05:02:28.152343Z",
     "shell.execute_reply.started": "2024-12-29T05:01:56.528431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5b22aa7a7c31>:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/working/Final_model.pth\"))\n",
      "100%|██████████| 1152/1152 [00:30<00:00, 37.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to evaluation.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.convert(\"L\")\n",
    "    image = np.array(image)\n",
    "    local_mean = np.mean(image)\n",
    "    thresh_image = np.where(image > (local_mean - 2), 255, 0)\n",
    "    return Image.fromarray(thresh_image.astype(np.uint8))\n",
    "\n",
    "class GlomeruliClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=2):\n",
    "        super(GlomeruliClassifier, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        num_features = 2048\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "def predict_images(model, image_folder, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image_name in tqdm(os.listdir(image_folder)):\n",
    "            if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(image_folder, image_name)\n",
    "                image = Image.open(img_path)\n",
    "                image = preprocess_image(image)\n",
    "                image = image.convert(\"RGB\")\n",
    "                image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "                outputs = model(image)\n",
    "                _, predicted = outputs.max(1)\n",
    "                predictions.append((image_name, predicted.item()))\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def save_predictions_to_csv(predictions, output_file):\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Image Name', 'Prediction'])\n",
    "        writer.writerows(predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load the model\n",
    "    model_path = \"./inception_v3_google-0cc3c7bd.pth\"\n",
    "    base_model = models.inception_v3(weights=None, init_weights=True)\n",
    "    base_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    base_model.fc = nn.Identity()\n",
    "    model = GlomeruliClassifier(base_model).to(device)\n",
    "\n",
    "    # Load the trained model weights\n",
    "    model.load_state_dict(torch.load(\"./Final_model.pth\"))\n",
    "\n",
    "    # Specify the folder containing the images to be classified\n",
    "    image_folder = \"./ResizedTestSet\"\n",
    "\n",
    "    # Predict classifications for all images in the folder\n",
    "    predictions = predict_images(model, image_folder, device)\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    output_file = \"evaluation.csv\"\n",
    "    save_predictions_to_csv(predictions, output_file)\n",
    "\n",
    "    print(f\"Predictions saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6390713,
     "sourceId": 10321818,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6390731,
     "sourceId": 10321836,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6390784,
     "sourceId": 10321915,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
